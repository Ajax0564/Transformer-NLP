{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import (AutoModel,AutoModelForMaskedLM, AutoTokenizer, LineByLineTextDataset,\n                         DataCollatorForLanguageModeling,Trainer, TrainingArguments)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-07T05:37:53.213181Z","iopub.execute_input":"2023-02-07T05:37:53.213508Z","iopub.status.idle":"2023-02-07T05:38:00.650663Z","shell.execute_reply.started":"2023-02-07T05:37:53.213430Z","shell.execute_reply":"2023-02-07T05:38:00.649777Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/data-for-distilation/Clinc_Train.csv')\ntest_data = pd.read_csv('../input/data-for-distilation/Clinc_valid.csv')\n\n\ndata = pd.concat([train_data,test_data])\n\ntext  = '\\n'.join(data.Text.tolist())\n\nwith open('text.txt','w') as f:\n    f.write(text)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T05:38:16.922419Z","iopub.execute_input":"2023-02-07T05:38:16.922774Z","iopub.status.idle":"2023-02-07T05:38:16.966307Z","shell.execute_reply.started":"2023-02-07T05:38:16.922740Z","shell.execute_reply":"2023-02-07T05:38:16.965450Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model_name = '../input/huggingfacedebertav3variants/deberta-v3-small'\nmodel = AutoModelForMaskedLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T05:38:46.442473Z","iopub.execute_input":"2023-02-07T05:38:46.442808Z","iopub.status.idle":"2023-02-07T05:38:55.665883Z","shell.execute_reply.started":"2023-02-07T05:38:46.442776Z","shell.execute_reply":"2023-02-07T05:38:55.665007Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at ../input/huggingfacedebertav3variants/deberta-v3-small were not used when initializing DebertaV2ForMaskedLM: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'deberta.embeddings.position_embeddings.weight']\n- This IS expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at ../input/huggingfacedebertav3variants/deberta-v3-small and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSpecial tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"text.txt\", #mention train text file here\n    block_size=128)\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n\ntraining_args =TrainingArguments(\n    output_dir=\"./Debertav3_small\", #select model path\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=12,\n#     save_steps=65,\n    save_total_limit=1,\n    prediction_loss_only=True,\n    report_to = \"none\")\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T05:39:04.128412Z","iopub.execute_input":"2023-02-07T05:39:04.128742Z","iopub.status.idle":"2023-02-07T05:39:14.089382Z","shell.execute_reply.started":"2023-02-07T05:39:04.128703Z","shell.execute_reply":"2023-02-07T05:39:14.088537Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-02-07T05:39:36.131956Z","iopub.execute_input":"2023-02-07T05:39:36.132313Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='2050' max='4590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2050/4590 06:20 < 07:51, 5.38 it/s, Epoch 1.34/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>3.967000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.444600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.121000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.934600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}